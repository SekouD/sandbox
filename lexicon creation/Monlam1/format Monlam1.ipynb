{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Monlam Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('monlamTb1.xml', 'r', -1, 'utf-8-sig') as f:\n",
    "    monlam = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = Soup(monlam, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicts = soup.array.findAll('dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monlam_dict = []\n",
    "for dic in dicts:\n",
    "    entry = dic.find_all('string')\n",
    "    lemma = entry[0].string\n",
    "    descr = entry[1].string.replace('\\n', '')\n",
    "    monlam_dict.append(lemma+' | '+descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./monlam/monlam1_total.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    f.write('\\n'.join(monlam_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## From txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./monlam/monlam1_total.txt','r', -1, 'utf-8-sig') as f:\n",
    "    content0 = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find all Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_entries = []\n",
    "for line in content0:\n",
    "    # separate the entry and the description\n",
    "    parts = line.split(' | ')\n",
    "    lemma = parts[0].strip()\n",
    "    #print(lemma, end = ' ')\n",
    "    # separate all sub-entries\n",
    "    sub_entries = re.split(r'༡(མིང|བྱ|རྒྱན|བསྣན|ཚབ|མཚུངས|སྒྲུབ|ཕྲད|འབོད|གྲངས|འཇལ|གྲོགས)་ཚིག', parts[1])\n",
    "    tags = ''\n",
    "    for i in range(1, len(sub_entries), 2):\n",
    "        tags += sub_entries[i]+'+'\n",
    "    if tags not in combined_entries:\n",
    "        combined_entries.append(tags)\n",
    "        if tags == '':\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(combined_entries)\n",
    "for e in combined_entries:\n",
    "    plus = re.findall('\\+', e)\n",
    "    print(plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correct missing tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list all the pos by looking at the \n",
    "pos = []\n",
    "for line in content0:\n",
    "    tags = re.findall(r' [༡༢][^ ༡༢༣༤༥༦༧༨༩༠.༽]+[ །]', line)\n",
    "    pos.extend(tags)\n",
    "pos = sorted(set(pos))\n",
    "\n",
    "for p in pos:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_missing = []\n",
    "num_inserted = []\n",
    "# insert the missing number in all tags that lack it\n",
    "for num, line in enumerate(content0):\n",
    "    #tag = re.findall(r'[། ][^༡༢](ཆོས་ལུགས།|ལོ་རྒྱུས།|ལྟ་གྲུབ།|རྩོམ་རིག|གསོ་རིག|ཆབ་སྲིད།|ཚན་རིག|བཟོ་རིག|རྩིས་རིག|ཁྲིམས་ལུགས།|དཔལ་འབྱོར།|དམག་དོན།|འཛིན་སྐྱོང་།|སྒྲ་རིག་པ།|ཤེས་ཡོན།|སློབ་གསོ།|ཚད་མ།|ཚད་མ་རིག་པ།|སྐྱེ་དངོས་རིག་པ།|ཟུར་ཆག|རྒྱ་གར།|རྒྱ་ནག|རྒྱ་ནག།|སོག་པོ།|མན་ཇུ།|དབྱིན་ཇི།|བལ་བོ།|མིང་གི་རྣམ་གྲངས།|མིང་གི་གྲངས།|མིང་གི་རྣམ་གྲངས་ལ།|ལྡོག་ཚིག|ལྡོག་ཚིིག|ལྡོག་ཚིག|ཉེ་ཚིག|ཟུར་མཆན།|ཡུལ་སྐད།|ཞེ་ས།|བརྙས་ཚིག|ལོག་སྐད།|དཔེ་ཆོས།|མངོན་བརྗོད།|བརྡ་རྙིང་།|བསྡུས་ཚིག|རྒྱུན་སྤྱོད།|བསྡུར་རིམ།|མ་འོངས་པ།|མ་འོངས།|ད་ལྟ་བ་།|ད་ལྟ་བ།|འདས་པ།|འདས།|སྐུ་ཚིག|སྐུར་ཚིག|སྐུལ་ཚིག|སྐུལ་ཚིག།|སྐུུལ་ཚིག) ', line)\n",
    "    tag = re.findall(r'\\| +(ཕྲད་ཚིག) ', line)\n",
    "    if tag != []:\n",
    "        #truc = re.sub(r'([^༡༢])(ཆོས་ལུགས།|ལོ་རྒྱུས།|ལྟ་གྲུབ།|རྩོམ་རིག|གསོ་རིག|ཆབ་སྲིད།|ཚན་རིག|བཟོ་རིག|རྩིས་རིག|ཁྲིམས་ལུགས།|དཔལ་འབྱོར།|དམག་དོན།|འཛིན་སྐྱོང་།|སྒྲ་རིག་པ།|ཤེས་ཡོན།|སློབ་གསོ།|ཚད་མ།|ཚད་མ་རིག་པ།|སྐྱེ་དངོས་རིག་པ།|ཟུར་ཆག|རྒྱ་གར།|རྒྱ་ནག|རྒྱ་ནག།|སོག་པོ།|མན་ཇུ།|དབྱིན་ཇི།|བལ་བོ།|མིང་གི་རྣམ་གྲངས།|མིང་གི་གྲངས།|མིང་གི་རྣམ་གྲངས་ལ།|ལྡོག་ཚིག|ལྡོག་ཚིིག|ལྡོག་ཚིག|ཉེ་ཚིག|ཟུར་མཆན།|ཡུལ་སྐད།|ཞེ་ས།|བརྙས་ཚིག|ལོག་སྐད།|དཔེ་ཆོས།|མངོན་བརྗོད།|བརྡ་རྙིང་།|བསྡུས་ཚིག|རྒྱུན་སྤྱོད།|བསྡུར་རིམ།|མ་འོངས་པ།|མ་འོངས།|ད་ལྟ་བ་།|ད་ལྟ་བ།|འདས་པ།|འདས།|སྐུ་ཚིག|སྐུར་ཚིག|སྐུལ་ཚིག|སྐུལ་ཚིག།|སྐུུལ་ཚིག) ', r'\\1༡\\2 ', line)\n",
    "        truc = re.sub('\\|( +)(ཕྲད་ཚིག) ', r'\\1༡\\2 ', line)\n",
    "        num_inserted.append(str(num)+truc)\n",
    "        num_missing.append(str(num)+line)\n",
    "with open('monlam_num_missing.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for line in num_missing:\n",
    "        f.write(line+'\\n')\n",
    "with open('monlam_num_inserted.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for line in num_inserted:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do : compare in Meld the two, put a '*' at the beginning of each line where the ༡ is not necessary, and delete the extra ones in lines where needed. Save the files in the monlam folder to not risk delete the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./monlam/monlam_num_inserted.txt', 'r', -1, 'utf-8-sig') as f:\n",
    "    inserted = [line.strip() for line in f.readlines()]\n",
    "monlam_corrected = content0\n",
    "\n",
    "# replace the bad entries by the ones from monlam_num_inserted.txt\n",
    "for line in inserted:\n",
    "    if not line.startswith('*'):\n",
    "        entry = [i for i in re.split('^([0-9]+)', line) if i != '']\n",
    "        monlam_corrected[int(entry[0])] = entry[1]\n",
    "\n",
    "with open('monlam1_total_corrected.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for line in monlam_corrected:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the modifications in monlam_errors.txt and save the file. The file is ready to be parsed !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('monlam1_total_corrected.txt', 'r', -1, 'utf-8-sig') as f:\n",
    "    content1 = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verbs = []\n",
    "rest = []\n",
    "for line in content1:\n",
    "    if '༡བྱ་ཚིག' in line and '༡རྒྱ་གར།' not in line:\n",
    "        verbs.append(line)\n",
    "    else:\n",
    "        rest.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shows the entry\n",
    "def show_entry(string):\n",
    "    for line in content1:\n",
    "        if line.startswith(string+'་ '):\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isRef(string):\n",
    "    test = False\n",
    "    if re.findall(r'[^༡༢](མ་འོངས་པ།|ད་ལྟ་བ།|འདས་པ།|སྐུལ་ཚིག)', string):\n",
    "        test = True\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add2dict(key, value, dic):\n",
    "    if key not in dic.keys():\n",
    "        dic[key] = value\n",
    "    else:\n",
    "        dic[key] = list(set(dic[key] + value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thadepa = 'ཐ་དད་པ'\n",
    "thamidepa = 'ཐ་མི་དད་པ'\n",
    "zugmigyur = 'གཟུགས་མི་འགྱུར་བ'\n",
    "empty = '###'\n",
    "unknown = 'བྱ་ཚིག'\n",
    "attr_sep = '_'\n",
    "pos_sep = '+'\n",
    "\n",
    "verbs_dict = {}\n",
    "for verb in verbs:\n",
    "    # separate the entry and the description\n",
    "    parts = verb.split(' | ')\n",
    "    lemma = parts[0].strip().replace('་', '')\n",
    "    \n",
    "    # separate all sub-entries\n",
    "    sub_entries = re.split(r'༡(མིང|བྱ|རྒྱན|བསྣན|ཚབ|མཚུངས|སྒྲུབ|ཕྲད|འབོད|གྲངས|འཇལ|གྲོགས)་ཚིག', parts[1])\n",
    "    # only keep the verb sub-entry\n",
    "    sub = ''\n",
    "    for i in range(len(sub_entries)):\n",
    "        if sub_entries[i] == 'བྱ':\n",
    "            sub = sub_entries[i+1]\n",
    "    \n",
    "    # separate meanings\n",
    "    meanings = re.split(r' [0-9]+\\. ', sub)\n",
    "    \n",
    "    # keep only verbs that are not references\n",
    "    #new_meanings = [m.strip() for m in meanings if not isRef(m) and m != '']\n",
    "    new_meanings = [m.strip() for m in meanings if m != '']\n",
    "    \n",
    "    if new_meanings != []:\n",
    "        for meaning in new_meanings:\n",
    "            #print(lemma, meaning)\n",
    "            # ཐ་དད་པ་ or ཐ་མི་དད་པ་\n",
    "            tha = empty\n",
    "            \n",
    "            if  'བྱ་བྱེད་ཐ་མི་དད་པ། ' in meaning: tha = thamidepa\n",
    "            elif 'བྱ་བྱེད་ཐ་དད་པ། ' in meaning: tha = thadepa\n",
    "            \n",
    "            # tenses\n",
    "            if ' གཟུགས་མི་འགྱུར་བ། ' in meaning:\n",
    "                add2dict(lemma, [zugmigyur+attr_sep+tha], verbs_dict)\n",
    "                #print({lemma : zugmigyur+attr_sep+tha})\n",
    "            else:\n",
    "                if 'མ་འོངས་པ།' in meaning or 'ད་ལྟ་བ།' in meaning or 'འདས་པ།' in meaning or 'སྐུལ་ཚིག' in meaning:\n",
    "                    if re.findall('(གི|ཀྱི|གྱི|ཡི|གིས|ཀྱིས|གྱིས|ཡིས)་(མ་འོངས་པ།|མ་འོངས།|ད་ལྟ་བ་།|ད་ལྟ་བ།|ལྟ་བ།|འདས་པ།|འདས།|སྐུ་ཚིག|སྐུར་ཚིག|སྐུལ་ཚིག|སྐུལ་ཚིག།|སྐུུལ་ཚིག) ', meaning) == []:\n",
    "                        tenses = re.findall(r'.(མ་འོངས་པ།|མ་འོངས།) ([^་\\s]+་?[ག།]) .(ད་ལྟ་བ་།|ད་ལྟ་བ།|ལྟ་བ།) ([^་\\s]+་?[ག།]) .(འདས་པ།|འདས།) ([^་\\s]+་?[ག།]) ?.?(སྐུ་ཚིག|སྐུར་ཚིག|སྐུལ་ཚིག|སྐུལ་ཚིག།|སྐུུལ་ཚིག)? ?([^་\\s]+་?[ག།])?', meaning)\n",
    "\n",
    "                        ############################\n",
    "                        # hack because of a strange behaviour of python : the structure of tenses is a tuple embedded in a list\n",
    "                        for t in tenses: \n",
    "                            temp = []\n",
    "                            for elt in t:\n",
    "                                if elt != '':\n",
    "                                    temp.append(elt)\n",
    "                        tenses = temp\n",
    "                        temp = []\n",
    "                        #\n",
    "                        ############################\n",
    "\n",
    "                        #print(tenses)\n",
    "                        for i in range(0, len(tenses)-1, 2):\n",
    "                            inflected = tenses[i+1].replace('།', '').replace('་', '')\n",
    "                            tense = tenses[i]\n",
    "                            add2dict(inflected, [lemma+attr_sep+tense+attr_sep+tha], verbs_dict)\n",
    "                            #print({inflected : lemma+attr_sep+tense+attr_sep+tha})\n",
    "                        # empty the tenses list for the next verb\n",
    "                        tenses = []\n",
    "                else:\n",
    "                    add2dict(lemma, [unknown+attr_sep+tha], verbs_dict)\n",
    "                    #print({lemma : unknown+attr_sep+tha})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find all alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alternative = []\n",
    "for verb in verbs:\n",
    "    if 'འབྲི་ཚུལ་' in verb:\n",
    "        alternative.append(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('alternative_verbs.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for line in alternative:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(alternative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply alternatives to verbs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./monlam/alternative_verbs.txt', 'r', -1, 'utf-8-sig') as f:\n",
    "    alt_content = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for verb in alt_content:\n",
    "    parts = verb.split(' = ')\n",
    "    lemma = parts[0]\n",
    "    pos = parts[1]+'_འབྲི་ཚུལ'\n",
    "    if lemma in verbs_dict.keys():\n",
    "        verbs_dict[lemma] = verbs_dict[lemma] + [pos]\n",
    "        #print(lemma, verbs_dict[lemma])\n",
    "    else:\n",
    "        verbs_dict[lemma] = [pos]\n",
    "        #print(verbs_dict[lemma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['འབྲུལ_འདས་པ།_འབྲི་ཚུལ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs_dict['ཕྲུལ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# flatten the pos list into a string\n",
    "for v in verbs_dict.keys():\n",
    "    flattened = '+'.join(list(set(verbs_dict[v])))\n",
    "    verbs_dict[v] = flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('monlam1_verbs.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for verb in sorted(verbs_dict.keys()):\n",
    "        f.write(verb+' | '+verbs_dict[verb]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_pos = []\n",
    "pos_tagged = []\n",
    "for entry in content1:\n",
    "    # separate the entry and the description\n",
    "    parts = entry.split(' | ')\n",
    "    lemma = parts[0].strip()\n",
    "    if lemma.endswith('་'):\n",
    "        lemma = lemma[:-1]\n",
    "    # separate all sub-entries\n",
    "    sub_entries = re.split(r'༡(མིང|བྱ|རྒྱན|བསྣན|ཚབ|མཚུངས|སྒྲུབ|ཕྲད|འབོད|གྲངས|འཇལ|གྲོགས)་ཚིག', parts[1])\n",
    "    \n",
    "    # only keep the verb sub-entry\n",
    "    sub = []\n",
    "    for i in range(len(sub_entries)):\n",
    "        if sub_entries[i] == 'བྱ' and '༡རྒྱ་གར།' not in sub_entries[i+1]:\n",
    "            if lemma not in verbs_dict.keys():\n",
    "                print(lemma, end= ' ')\n",
    "            else:\n",
    "                sub.append('བྱ་ཚིག:'+verbs_dict[lemma])\n",
    "        else:\n",
    "            if sub_entries[i] in ['མིང', 'བྱ', 'རྒྱན', 'བསྣན', 'ཚབ', 'མཚུངས', 'སྒྲུབ', 'ཕྲད', 'འབོད', 'གྲངས', 'འཇལ', 'གྲོགས']:\n",
    "                tags = re.findall(r'[། ]?[^་ ](ཆོས་ལུགས།|ལོ་རྒྱུས།|ལྟ་གྲུབ།|རྩོམ་རིག|གསོ་རིག|ཆབ་སྲིད།|ཚན་རིག|བཟོ་རིག|རྩིས་རིག|ཁྲིམས་ལུགས།|དཔལ་འབྱོར།|དམག་དོན།|འཛིན་སྐྱོང་།|སྒྲ་རིག་པ།|ཤེས་ཡོན།|སློབ་གསོ།|ཚད་མ།|ཚད་མ་རིག་པ།|སྐྱེ་དངོས་རིག་པ།|ཟུར་ཆག|རྒྱ་གར།|རྒྱ་ནག|རྒྱ་ནག།|སོག་པོ།|མན་ཇུ།|དབྱིན་ཇི།|བལ་བོ།|མིང་གི་རྣམ་གྲངས།|མིང་གི་གྲངས།|མིང་གི་རྣམ་གྲངས་ལ།|ལྡོག་ཚིག|ལྡོག་ཚིིག|ལྡོག་ཚིག|ཉེ་ཚིག|ཟུར་མཆན།|ཡུལ་སྐད།|ཞེ་ས།|བརྙས་ཚིག|ལོག་སྐད།|དཔེ་ཆོས།|མངོན་བརྗོད།|བརྡ་རྙིང་།|བསྡུས་ཚིག|རྒྱུན་སྤྱོད།|བསྡུར་རིམ།|མ་འོངས་པ།|མ་འོངས།|ད་ལྟ་བ་།|ད་ལྟ་བ།|འདས་པ།|འདས།|སྐུ་ཚིག|སྐུར་ཚིག|སྐུལ་ཚིག|སྐུལ་ཚིག།|སྐུུལ་ཚིག) ', sub_entries[i+1])\n",
    "                sub.append(sub_entries[i]+'་ཚིག:'+'_'.join(tags))\n",
    "    \n",
    "    total_tags = '/'.join(sub)\n",
    "    if total_tags != '':\n",
    "        pos_tagged.append(lemma+'—'+total_tags)\n",
    "    else:\n",
    "        no_pos.append(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verbs_dict['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('monlam1_pos.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    f.write('\\n'.join(pos_tagged))\n",
    "with open('monlam1_no_pos.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    f.write('\\n'.join(no_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for truc in ['གདིང', 'གནན', 'གྲུས', 'ཆུམ', 'ཉར', 'ཉོར', 'དགོག', 'དགྱེད', 'དབྲབ', 'ཕིག', 'ཕྲད', 'ཕྲུལ', 'ཕྲོས', 'བཀོག', 'བང', 'བངས', 'བཅོ', 'བཏིངས', 'བཙགས', 'བཟབ', 'བརྒྱུ', 'བརྒྱུས', 'བརྟིབ', 'བརྟིབས', 'བཤག', 'བཤགས', 'བསྒོངས', 'བསྒོངས', 'བསྒྲོག', 'བསྒྲོགས', 'བསླ', 'བསླས', 'ཚོལ', 'ཟླུམས', 'འཁྲིས', 'འགེལ', 'འཆགས', 'འཆོགས', 'འཆོབས', 'འཇབས', 'འཇས', 'འཐུས', 'འདིང', 'འདོས', 'འདྲུབས', 'འཕྱོགས', 'འཕྲད', 'འཚོབས', 'རྐོམས', 'རྒྱུད', 'རྒྱུས', 'རྟིབས', 'ལྟུང', 'ལྟུངས', 'ལྡིང', 'ལྡིང', 'ཤོགས', 'སྒོང', 'སྒོངས', 'སྨྲོས', 'སྲོགས']:\n",
    "    show_entry(truc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "show_entry('ཉོར')\n",
    "verbs_dict['བཤག']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### basic tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('monlam1_pos.txt', 'r', -1, 'utf-8-sig') as f:\n",
    "    content2 = [line.strip() for line in f.readlines()]\n",
    "\n",
    "basic_pos = {}\n",
    "for line in content2:\n",
    "    parts = line.split('—')\n",
    "    form = parts[0]\n",
    "    pos = re.findall(r' ?([^ \\:]+)\\:', parts[1])\n",
    "    basic_pos[form] = pos\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('monlam1_verbs.txt', 'r', -1, 'utf-8-sig') as f:\n",
    "    content3 = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verb_tenses = {}\n",
    "for verb in content3:\n",
    "    entry = verb.split(' | ')\n",
    "    form = entry[0]\n",
    "    tags = entry[1].split('+')\n",
    "    pos = []\n",
    "    for tag in tags:\n",
    "        parts = tag.split('_')\n",
    "        if len(parts) == 3:\n",
    "            pos.append(parts[1])\n",
    "        if len(parts) == 2:\n",
    "            pos.append(parts[0])\n",
    "    pos = list(set(pos))\n",
    "    verb_tenses[form] = '-'.join(pos)\n",
    "#print(verb_tenses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for entry in basic_pos.keys():\n",
    "    for num, pos in enumerate(basic_pos[entry]):\n",
    "        if pos == 'བྱ་ཚིག' and entry in verb_tenses.keys():\n",
    "            basic_pos[entry][num] = basic_pos[entry][num] +'|'+ verb_tenses[entry]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('monlam1_basic_pos.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for entry in sorted(basic_pos.keys()):\n",
    "        f.write(entry+'\\t'+'_'.join(basic_pos[entry])+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

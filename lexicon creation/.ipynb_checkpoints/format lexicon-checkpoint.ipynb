{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hill Lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('./2016-04-06-lexicon.txt', 'r', -1, 'utf-8-sig') as f:\n",
    "    content = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexicon = {}\n",
    "for line in content:\n",
    "    parts = line.split('\\t')\n",
    "    entry = parts[0]\n",
    "    pos = [elt.strip(' -') for elt in parts[1:]]\n",
    "    if entry.endswith('་'):\n",
    "        entry = entry[:-1]\n",
    "    if entry in lexicon.keys():\n",
    "        for p in pos:\n",
    "            if p not in lexicon[entry]:\n",
    "                lexicon[entry].append(p)\n",
    "    else:\n",
    "        lexicon[entry] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flat_lexicon = {}\n",
    "for entry in lexicon.keys():\n",
    "    flat_lexicon[entry] = '_'.join(lexicon[entry])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pos_list = []\n",
    "for entry in lexicon.keys():\n",
    "    pos_list.extend(lexicon[entry])\n",
    "pos_set = set(pos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(sorted(pos_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('hill_lexicon.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for entry in no_prop.keys():\n",
    "        f.write(entry+'***'+no_prop[entry]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cases = {}\n",
    "for entry in flat_lexicon.keys():\n",
    "    pos = flat_lexicon[entry]\n",
    "    if 'case' in pos and 'cv' not in pos:\n",
    "        print('nocv: ', entry, pos)\n",
    "    #elif 'case' not in pos and 'cv' in pos:\n",
    "     #   print('nocase: ', entry, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for entry in flat_lexicon.keys():\n",
    "    pos = flat_lexicon[entry]\n",
    "    if 'case' not in pos and 'cv' in pos:\n",
    "        print('nocase: ', entry, pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_prop = {}\n",
    "prop = []\n",
    "for entry in flat_lexicon.keys():\n",
    "    pos = flat_lexicon[entry]\n",
    "    if 'prop' in pos:\n",
    "        prop.append(entry)\n",
    "    else:\n",
    "        no_prop[entry] = pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(prop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(one_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(flat_lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "22279-15963"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "6316*100/22279"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Monlam Lexicon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as Soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('monlamTb1.xml', 'r', -1, 'utf-8-sig') as f:\n",
    "    monlam = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = Soup(monlam, 'lxml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dicts = soup.array.findAll('dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "monlam_dict = []\n",
    "for dic in dicts:\n",
    "    entry = dic.find_all('string')\n",
    "    lemma = entry[0].string\n",
    "    descr = entry[1].string.replace('\\n', '')\n",
    "    monlam_dict.append(lemma+' | '+descr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./monlam/monlam1_total.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    f.write('\\n'.join(monlam_dict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## From txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./monlam/monlam1_total.txt','r', -1, 'utf-8-sig') as f:\n",
    "    content0 = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find all Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "combined_entries = []\n",
    "for line in content0:\n",
    "    # separate the entry and the description\n",
    "    parts = line.split(' | ')\n",
    "    lemma = parts[0].strip()\n",
    "    #print(lemma, end = ' ')\n",
    "    # separate all sub-entries\n",
    "    sub_entries = re.split(r'༡(མིང|བྱ|རྒྱན|བསྣན|ཚབ|མཚུངས|སྒྲུབ|ཕྲད|འབོད|གྲངས|འཇལ|གྲོགས)་ཚིག', parts[1])\n",
    "    tags = ''\n",
    "    for i in range(1, len(sub_entries), 2):\n",
    "        tags += sub_entries[i]+'+'\n",
    "    if tags not in combined_entries:\n",
    "        combined_entries.append(tags)\n",
    "        if tags == '':\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(combined_entries)\n",
    "for e in combined_entries:\n",
    "    plus = re.findall('\\+', e)\n",
    "    print(plus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correct missing tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# list all the pos by looking at the \n",
    "pos = []\n",
    "for line in content0:\n",
    "    tags = re.findall(r' [༡༢][^ ༡༢༣༤༥༦༧༨༩༠.༽]+[ །]', line)\n",
    "    pos.extend(tags)\n",
    "pos = sorted(set(pos))\n",
    "\n",
    "for p in pos:\n",
    "    print(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_missing = []\n",
    "num_inserted = []\n",
    "# insert the missing number in all tags that lack it\n",
    "for num, line in enumerate(content0):\n",
    "    #tag = re.findall(r'[། ][^༡༢](ཆོས་ལུགས།|ལོ་རྒྱུས།|ལྟ་གྲུབ།|རྩོམ་རིག|གསོ་རིག|ཆབ་སྲིད།|ཚན་རིག|བཟོ་རིག|རྩིས་རིག|ཁྲིམས་ལུགས།|དཔལ་འབྱོར།|དམག་དོན།|འཛིན་སྐྱོང་།|སྒྲ་རིག་པ།|ཤེས་ཡོན།|སློབ་གསོ།|ཚད་མ།|ཚད་མ་རིག་པ།|སྐྱེ་དངོས་རིག་པ།|ཟུར་ཆག|རྒྱ་གར།|རྒྱ་ནག|རྒྱ་ནག།|སོག་པོ།|མན་ཇུ།|དབྱིན་ཇི།|བལ་བོ།|མིང་གི་རྣམ་གྲངས།|མིང་གི་གྲངས།|མིང་གི་རྣམ་གྲངས་ལ།|ལྡོག་ཚིག|ལྡོག་ཚིིག|ལྡོག་ཚིག|ཉེ་ཚིག|ཟུར་མཆན།|ཡུལ་སྐད།|ཞེ་ས།|བརྙས་ཚིག|ལོག་སྐད།|དཔེ་ཆོས།|མངོན་བརྗོད།|བརྡ་རྙིང་།|བསྡུས་ཚིག|རྒྱུན་སྤྱོད།|བསྡུར་རིམ།|མ་འོངས་པ།|མ་འོངས།|ད་ལྟ་བ་།|ད་ལྟ་བ།|འདས་པ།|འདས།|སྐུ་ཚིག|སྐུར་ཚིག|སྐུལ་ཚིག|སྐུལ་ཚིག།|སྐུུལ་ཚིག) ', line)\n",
    "    tag = re.findall(r'\\| +(ཕྲད་ཚིག) ', line)\n",
    "    if tag != []:\n",
    "        #truc = re.sub(r'([^༡༢])(ཆོས་ལུགས།|ལོ་རྒྱུས།|ལྟ་གྲུབ།|རྩོམ་རིག|གསོ་རིག|ཆབ་སྲིད།|ཚན་རིག|བཟོ་རིག|རྩིས་རིག|ཁྲིམས་ལུགས།|དཔལ་འབྱོར།|དམག་དོན།|འཛིན་སྐྱོང་།|སྒྲ་རིག་པ།|ཤེས་ཡོན།|སློབ་གསོ།|ཚད་མ།|ཚད་མ་རིག་པ།|སྐྱེ་དངོས་རིག་པ།|ཟུར་ཆག|རྒྱ་གར།|རྒྱ་ནག|རྒྱ་ནག།|སོག་པོ།|མན་ཇུ།|དབྱིན་ཇི།|བལ་བོ།|མིང་གི་རྣམ་གྲངས།|མིང་གི་གྲངས།|མིང་གི་རྣམ་གྲངས་ལ།|ལྡོག་ཚིག|ལྡོག་ཚིིག|ལྡོག་ཚིག|ཉེ་ཚིག|ཟུར་མཆན།|ཡུལ་སྐད།|ཞེ་ས།|བརྙས་ཚིག|ལོག་སྐད།|དཔེ་ཆོས།|མངོན་བརྗོད།|བརྡ་རྙིང་།|བསྡུས་ཚིག|རྒྱུན་སྤྱོད།|བསྡུར་རིམ།|མ་འོངས་པ།|མ་འོངས།|ད་ལྟ་བ་།|ད་ལྟ་བ།|འདས་པ།|འདས།|སྐུ་ཚིག|སྐུར་ཚིག|སྐུལ་ཚིག|སྐུལ་ཚིག།|སྐུུལ་ཚིག) ', r'\\1༡\\2 ', line)\n",
    "        truc = re.sub('\\|( +)(ཕྲད་ཚིག) ', r'\\1༡\\2 ', line)\n",
    "        num_inserted.append(str(num)+truc)\n",
    "        num_missing.append(str(num)+line)\n",
    "with open('monlam_num_missing.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for line in num_missing:\n",
    "        f.write(line+'\\n')\n",
    "with open('monlam_num_inserted.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for line in num_inserted:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do : compare in Meld the two, put a '*' at the beginning of each line where the ༡ is not necessary, and delete the extra ones in lines where needed. Save the files in the monlam folder to not risk delete the work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./monlam/monlam_num_inserted.txt', 'r', -1, 'utf-8-sig') as f:\n",
    "    inserted = [line.strip() for line in f.readlines()]\n",
    "monlam_corrected = content0\n",
    "\n",
    "# replace the bad entries by the ones from monlam_num_inserted.txt\n",
    "for line in inserted:\n",
    "    if not line.startswith('*'):\n",
    "        entry = [i for i in re.split('^([0-9]+)', line) if i != '']\n",
    "        monlam_corrected[int(entry[0])] = entry[1]\n",
    "\n",
    "with open('monlam1_total_corrected.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for line in monlam_corrected:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Insert the modifications in monlam_errors.txt and save the file. The file is ready to be parsed !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('monlam1_total_corrected.txt', 'r', -1, 'utf-8-sig') as f:\n",
    "    content1 = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "verbs = []\n",
    "rest = []\n",
    "for line in content1:\n",
    "    if '༡བྱ་ཚིག' in line and '༡རྒྱ་གར།' not in line:\n",
    "        verbs.append(line)\n",
    "    else:\n",
    "        rest.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# shows the entry\n",
    "def show_entry(string):\n",
    "    for line in content1:\n",
    "        if line.startswith(string+'་ '):\n",
    "            print(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def isRef(string):\n",
    "    test = False\n",
    "    if re.findall(r'[^༡༢](མ་འོངས་པ།|ད་ལྟ་བ།|འདས་པ།|སྐུལ་ཚིག)', string):\n",
    "        test = True\n",
    "    return test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add2dict(key, value, dic):\n",
    "    if key not in dic.keys():\n",
    "        dic[key] = value\n",
    "    else:\n",
    "        dic[key] = list(set(dic[key] + value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "thadepa = 'ཐ་དད་པ'\n",
    "thamidepa = 'ཐ་མི་དད་པ'\n",
    "zugmigyur = 'གཟུགས་མི་འགྱུར་བ'\n",
    "empty = '###'\n",
    "unknown = 'བྱ་ཚིག'\n",
    "attr_sep = '_'\n",
    "pos_sep = '+'\n",
    "\n",
    "verbs_dict = {}\n",
    "for verb in verbs:\n",
    "    # separate the entry and the description\n",
    "    parts = verb.split(' | ')\n",
    "    lemma = parts[0].strip().replace('་', '')\n",
    "    \n",
    "    # separate all sub-entries\n",
    "    sub_entries = re.split(r'༡(མིང|བྱ|རྒྱན|བསྣན|ཚབ|མཚུངས|སྒྲུབ|ཕྲད|འབོད|གྲངས|འཇལ|གྲོགས)་ཚིག', parts[1])\n",
    "    # only keep the verb sub-entry\n",
    "    sub = ''\n",
    "    for i in range(len(sub_entries)):\n",
    "        if sub_entries[i] == 'བྱ':\n",
    "            sub = sub_entries[i+1]\n",
    "    \n",
    "    # separate meanings\n",
    "    meanings = re.split(r' [0-9]+\\. ', sub)\n",
    "    \n",
    "    # keep only verbs that are not references\n",
    "    #new_meanings = [m.strip() for m in meanings if not isRef(m) and m != '']\n",
    "    new_meanings = [m.strip() for m in meanings if m != '']\n",
    "    \n",
    "    if new_meanings != []:\n",
    "        for meaning in new_meanings:\n",
    "            #print(lemma, meaning)\n",
    "            # ཐ་དད་པ་ or ཐ་མི་དད་པ་\n",
    "            tha = empty\n",
    "            \n",
    "            if  'བྱ་བྱེད་ཐ་མི་དད་པ། ' in meaning: tha = thamidepa\n",
    "            elif 'བྱ་བྱེད་ཐ་དད་པ། ' in meaning: tha = thadepa\n",
    "            \n",
    "            # tenses\n",
    "            if ' གཟུགས་མི་འགྱུར་བ། ' in meaning:\n",
    "                add2dict(lemma, [zugmigyur+attr_sep+tha], verbs_dict)\n",
    "                #print({lemma : zugmigyur+attr_sep+tha})\n",
    "            else:\n",
    "                if 'མ་འོངས་པ།' in meaning or 'ད་ལྟ་བ།' in meaning or 'འདས་པ།' in meaning or 'སྐུལ་ཚིག' in meaning:\n",
    "                    tenses = re.findall(r'.(མ་འོངས་པ།|མ་འོངས།) ([^་\\s]+་?[ག།]) .(ད་ལྟ་བ་།|ད་ལྟ་བ།|ལྟ་བ།) ([^་\\s]+་?[ག།]) .(འདས་པ།|འདས།) ([^་\\s]+་?[ག།]) ?.?(སྐུ་ཚིག|སྐུར་ཚིག|སྐུལ་ཚིག|སྐུལ་ཚིག།|སྐུུལ་ཚིག)? ?([^་\\s]+་?[ག།])?', meaning)\n",
    "                    \n",
    "                    ############################\n",
    "                    # hack because of a strange behaviour of python : the structure of tenses is a tuple embedded in a list\n",
    "                    for t in tenses: \n",
    "                        temp = []\n",
    "                        for elt in t:\n",
    "                            if elt != '':\n",
    "                                temp.append(elt)\n",
    "                    tenses = temp\n",
    "                    temp = []\n",
    "                    #\n",
    "                    ############################\n",
    "\n",
    "                    #print(tenses)\n",
    "                    for i in range(0, len(tenses)-1, 2):\n",
    "                        inflected = tenses[i+1].replace('།', '').replace('་', '')\n",
    "                        tense = tenses[i]\n",
    "                        add2dict(inflected, [lemma+attr_sep+tense+attr_sep+tha], verbs_dict)\n",
    "                        #print({inflected : lemma+attr_sep+tense+attr_sep+tha})\n",
    "                    # empty the tenses list for the next verb\n",
    "                    tenses = []\n",
    "                else:\n",
    "                    add2dict(lemma, [unknown+attr_sep+tha], verbs_dict)\n",
    "                    #print({lemma : unknown+attr_sep+tha})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative Verbs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find all alternatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alternative = []\n",
    "for verb in verbs:\n",
    "    if 'འབྲི་ཚུལ་' in verb:\n",
    "        alternative.append(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('alternative_verbs.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for line in alternative:\n",
    "        f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(len(alternative))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### apply alternatives to verbs_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('./monlam/alternative_verbs.txt', 'r', -1, 'utf-8-sig') as f:\n",
    "    alt_content = [line.strip() for line in f.readlines()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for verb in alt_content:\n",
    "    parts = verb.split(' = ')\n",
    "    lemma = parts[0]\n",
    "    pos = parts[1]+'_འབྲི་ཚུལ'\n",
    "    if lemma in verbs_dict.keys():\n",
    "        verbs_dict[lemma] = verbs_dict[lemma] + [pos]\n",
    "        #print(lemma, verbs_dict[lemma])\n",
    "    else:\n",
    "        verbs_dict[lemma] = [pos]\n",
    "        #print(verbs_dict[lemma])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ཕྲུལ_འདས་པ།_ཐ་མི་དད་པ']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verbs_dict['ཕྲུལ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# flatten the pos list into a string\n",
    "for v in verbs_dict.keys():\n",
    "    flattened = '+'.join(list(set(verbs_dict[v])))\n",
    "    verbs_dict[v] = flattened"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('monlam1_verbs.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    for verb in sorted(verbs_dict.keys()):\n",
    "        f.write(verb+' | '+verbs_dict[verb]+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_pos = []\n",
    "pos_tagged = []\n",
    "for entry in content1:\n",
    "    # separate the entry and the description\n",
    "    parts = entry.split(' | ')\n",
    "    lemma = parts[0].strip()\n",
    "    if lemma.endswith('་'):\n",
    "        lemma = lemma[:-1]\n",
    "    # separate all sub-entries\n",
    "    sub_entries = re.split(r'༡(མིང|བྱ|རྒྱན|བསྣན|ཚབ|མཚུངས|སྒྲུབ|ཕྲད|འབོད|གྲངས|འཇལ|གྲོགས)་ཚིག', parts[1])\n",
    "    \n",
    "    # only keep the verb sub-entry\n",
    "    sub = []\n",
    "    for i in range(len(sub_entries)):\n",
    "        if sub_entries[i] == 'བྱ' and '༡རྒྱ་གར།' not in sub_entries[i+1]:\n",
    "            if lemma not in verbs_dict.keys():\n",
    "                print(lemma, end= ' ')\n",
    "            else:\n",
    "                sub.append('བྱ་ཚིག:'+verbs_dict[lemma])\n",
    "        else:\n",
    "            if sub_entries[i] in ['མིང', 'བྱ', 'རྒྱན', 'བསྣན', 'ཚབ', 'མཚུངས', 'སྒྲུབ', 'ཕྲད', 'འབོད', 'གྲངས', 'འཇལ', 'གྲོགས']:\n",
    "                tags = re.findall(r'[། ]?[^་ ](ཆོས་ལུགས།|ལོ་རྒྱུས།|ལྟ་གྲུབ།|རྩོམ་རིག|གསོ་རིག|ཆབ་སྲིད།|ཚན་རིག|བཟོ་རིག|རྩིས་རིག|ཁྲིམས་ལུགས།|དཔལ་འབྱོར།|དམག་དོན།|འཛིན་སྐྱོང་།|སྒྲ་རིག་པ།|ཤེས་ཡོན།|སློབ་གསོ།|ཚད་མ།|ཚད་མ་རིག་པ།|སྐྱེ་དངོས་རིག་པ།|ཟུར་ཆག|རྒྱ་གར།|རྒྱ་ནག|རྒྱ་ནག།|སོག་པོ།|མན་ཇུ།|དབྱིན་ཇི།|བལ་བོ།|མིང་གི་རྣམ་གྲངས།|མིང་གི་གྲངས།|མིང་གི་རྣམ་གྲངས་ལ།|ལྡོག་ཚིག|ལྡོག་ཚིིག|ལྡོག་ཚིག|ཉེ་ཚིག|ཟུར་མཆན།|ཡུལ་སྐད།|ཞེ་ས།|བརྙས་ཚིག|ལོག་སྐད།|དཔེ་ཆོས།|མངོན་བརྗོད།|བརྡ་རྙིང་།|བསྡུས་ཚིག|རྒྱུན་སྤྱོད།|བསྡུར་རིམ།|མ་འོངས་པ།|མ་འོངས།|ད་ལྟ་བ་།|ད་ལྟ་བ།|འདས་པ།|འདས།|སྐུ་ཚིག|སྐུར་ཚིག|སྐུལ་ཚིག|སྐུལ་ཚིག།|སྐུུལ་ཚིག) ', sub_entries[i+1])\n",
    "                sub.append(sub_entries[i]+'་ཚིག:'+'_'.join(tags))\n",
    "    \n",
    "    total_tags = ' '.join(sub)\n",
    "    if total_tags != '':\n",
    "        pos_tagged.append(lemma+'—'+total_tags)\n",
    "    else:\n",
    "        no_pos.append(entry)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('monlam1_pos.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    f.write('\\n'.join(pos_tagged))\n",
    "with open('monlam1_no_pos.txt', 'w', -1, 'utf-8-sig') as f:\n",
    "    f.write('\\n'.join(no_pos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ལྡོག་ཁྱབ་ཀྱི་མཚན་ཉིད་ཟུར་དུ་ཉིད་སྨོས་པ་ | ༡བྱ་ཚིག ༡ཚད་མ། དེ་ཡང་། པཎ་ཆེན་བསོད་ནམས་གྲགས་པའི་རྣམ་འགྲེལ་དགོངས་པ་རབ་གསལ་ལས། ཉིད་སྨོས་པ་ལ་དགོས་པ་ཡོད་དེ། མི་རྟག་པར་དུང་སྒྲ་རྩོལ་བྱུང་དུ་སྒྲུབ་པའི་ལྡོག་ཁྱབ་ཡིན་པ་བཅད་པའི་ཆེད་དུ་ཡིན་པའི་ཕྱིར། ཚིག་དེ་ལ་བརྟེན་ནས་དེ་ཡིན་པ་ཁེགས་པར་འགྱུར་ཏེ། མི་རྟག་པར་དུང་སྒྲ་རྩོལ་བྱུང་དུ་སྒྲུབ་པའི་མི་མཐུན་ཕྱོགས་ལ་མེད་པ་ཁོ་ན་མིན་པ་སྟེ། དེ་སྒྲུབ་ཀྱི་མི་མཐུན་ཕྱོགས་ཡིན་ན། མི་རྟག་པ་ཡིན་པས་ཀྱང་མ་ཁྱབ། མ་ཡིན་པས་ཀྱང་མ་ཁྱབ་པའི་ཕྱིར་ཏེ། དེ་སྒྲུབ་ཀྱི་མི་མཐུན་ཕྱོགས་གློག་མི་རྟག་པ་ཡིན། ནམ་མཁའ་དེ་མ་ཡིན་པའི་ཕྱིར། དེ་ལྟར་ཡང་། འཐད་ལྡན་ཆུང་བ་ལས། ཉིད་སྨོས་པ་ནི། མི་མཐུན་པའི་ཕྱོགས་གཅིག་ལ་ཐུན་མོང་དུ་ཡོད་པ་བསལ་བ་ཡིན་ཏེ། རྩོལ་བ་ལས་བྱུང་བ་ཉིད་བསྒྲུབ་པར་བྱ་བ་ལ་མི་རྟག་པ་ཉིད་ནི་མི་མཐུན་པའི་ཕྱོགས་གཅིག་གློག་ལ་སོགས་པ་ནི་ཡོད་པ་ཡིན་ལ། ནམ་མཁའ་ལ་སོགས་པ་ལ་ནི་མེད་པ་ཡིན་ནོ། །དེ་བས་ན་ངེས་འབྱེད་པ་འདི་བསལ་ཏོ། །\n"
     ]
    }
   ],
   "source": [
    "show_entry('ལྡོག་ཁྱབ་ཀྱི་མཚན་ཉིད་ཟུར་དུ་ཉིད་སྨོས་པ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

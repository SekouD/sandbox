{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punctuation = [\" \", \"༄\", \"༅\", \"࿓\", \"࿔\", \"༇\", \"༆\", \"༈\", \"།\", \"༎\", \"༏\", \"༐\", \"༑\", \"༔\",\"་\", \"༌\", \"༼\", \"༽\", \"༒\", \"༓\", \"ཿ\"]\n",
    "\n",
    "merged_aa_cases = [\"འི\", \"འིས\", \"འང\", \"འམ\", \"འོ\"]\n",
    "other_merged = [\"ས\", \"ར\"]\n",
    "\n",
    "\n",
    "dreldra = ['གི', 'ཀྱི', 'གྱི', 'ཡི']\n",
    "jedra = ['གིས', 'ཀྱིས', 'གྱིས', 'ཡིས']\n",
    "ladon = ['སུ', 'ཏུ', 'དུ', 'རུ']\n",
    "lhagche = ['སྟེ', 'ཏེ', 'དེ']\n",
    "gyendu = ['གམ', 'ངམ', 'དམ', 'ནམ', 'བམ', 'མམ', 'རམ', 'ལམ', 'སམ', 'ཏམ']\n",
    "dagdra = ['པ', 'པོ', 'བ', 'བོ']\n",
    "lardu = ['གོ', 'ངོ', 'དོ', 'ནོ', 'བོ', 'མོ', 'འོ', 'རོ', 'ལོ', 'སོ', 'ཏོ']\n",
    "separate_particles = dreldra + jedra + ladon + lhagche + gyendu + dagdra + lardu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "current_layers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class prepareTib:\n",
    "    ''' Dealing with the punctuation of Tibetan '''\n",
    "    global current_layers\n",
    "    current_layers = {} # initiate the layers' dictionary for the current file\n",
    "    \n",
    "    def __init__(self, tibstring):\n",
    "        self.raw = tibstring\n",
    "        self.punct = punctuation\n",
    "        self.layers = current_layers\n",
    "        \n",
    "        #####################################################\n",
    "        # Prepare the layer of syllables\n",
    "        #ne pas oublier d’implémenter le layer des linebreaks\n",
    "        #import re\n",
    "        #re.split('([ ༄༅࿓࿔༇༆༈།༎༏༐༑༔་༌༼༽༒༓ཿ]+)', '༄༅།། །།བཅོམ་ལྡན་འདས་དེའི་ཚེ་ན་ཚེ་དང་ལྡན་པ་ཀུན་དགང་།ཀུན ་ཀུན་')[1:-1]\n",
    "        linebreaks_layer = []\n",
    "        syllables_layer = []\n",
    "        puncts = []\n",
    "        syl = ''\n",
    "        for index, char in enumerate(self.raw):\n",
    "            if index == 0:\n",
    "                if char in self.punct:\n",
    "                    puncts.append(char)\n",
    "                else:\n",
    "                    syl += char\n",
    "            else:\n",
    "                if char not in self.punct and self.raw[index-1] in self.punct:\n",
    "                    if '\\r\\n' in syl:\n",
    "                        syllables_layer.append((syl.replace('\\r\\n', ''), puncts))\n",
    "                        linebreaks_layer.append('\\n')\n",
    "                    elif '\\n' in syl:\n",
    "                        syllables_layer.append((syl.replace('\\n', ''), puncts))\n",
    "                        linebreaks_layer.append('\\n')\n",
    "                    else:\n",
    "                        syllables_layer.append((syl, puncts))\n",
    "                        linebreaks_layer.append('')\n",
    "                        \n",
    "                    puncts = []\n",
    "                    syl = char\n",
    "                elif char not in self.punct:\n",
    "                    syl += char\n",
    "                elif char in self.punct:\n",
    "                    puncts.append(char)\n",
    "        # add last syllable + its punctuation\n",
    "        if syl != '':\n",
    "            if '\\r\\n' in syl:\n",
    "                syllables_layer.append((syl.replace('\\r\\n', ''), puncts))\n",
    "                linebreaks_layer.append('\\n')\n",
    "            elif '\\n' in syl:\n",
    "                syllables_layer.append((syl.replace('\\n', ''), puncts))\n",
    "                linebreaks_layer.append('\\n')\n",
    "            else:\n",
    "                syllables_layer.append((syl, puncts))\n",
    "                linebreaks_layer.append('')\n",
    "            \n",
    "        self.layers['linebreaks'] = linebreaks_layer\n",
    "        self.layers['syllables'] = syllables_layer\n",
    "        #\n",
    "        ################################################################\n",
    "        \n",
    "    def syl_tuples(self):\n",
    "        tuples = self.layers['syllables']\n",
    "        return [(t[0], ''.join(t[1])) for t in tuples]\n",
    "    \n",
    "    def all_punct(self):\n",
    "        tuples = prepareTib.syl_tuples(self)\n",
    "        return [t[0]+t[1] for t in tuples]\n",
    "    \n",
    "    def syls_only(self):\n",
    "        tuples = self.layers['syllables']\n",
    "        return [t[0] for t in tuples]\n",
    "    \n",
    "    def tsheks_only(self):\n",
    "        tuples = prepareTib.syl_tuples(self)\n",
    "        return [t[0]+'་' for t in tuples]\n",
    "    \n",
    "    def no_tshek(self):\n",
    "        tuples = prepareTib.syl_tuples(self)\n",
    "        no_tshek = []\n",
    "        for t in tuples:\n",
    "            if '་' in t[1]:\n",
    "                no_tshek.append(t[0]+t[1].replace('་', ''))\n",
    "            else :\n",
    "                no_tshek.append(t[0]+t[1])\n",
    "        return no_tshek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class segment:\n",
    "    '''segment a given string of Tibetan'''\n",
    "    def __init__(self):\n",
    "        self.m_particles = merged_aa_cases # ས and ར are not yet supported\n",
    "        self.s_particles = separate_particles\n",
    "        self.layers = current_layers\n",
    "        \n",
    "        #####################################################\n",
    "        # pre-segmentation : finding all particles in the text\n",
    "        particles_layer = []\n",
    "        for t in self.layers['syllables']:\n",
    "            # find wether the syllable ends with a merged aa case\n",
    "            m_part = ''\n",
    "            for aa in self.m_particles:\n",
    "                if t[0].endswith(aa):\n",
    "                    m_part = aa\n",
    "            \n",
    "            if t[0] in self.s_particles:\n",
    "                particles_layer.append(t[0])\n",
    "            elif m_part != '':\n",
    "                particles_layer.append((t[0].replace(m_part, ''), m_part))\n",
    "            else:\n",
    "                particles_layer.append('')\n",
    "                \n",
    "        self.layers['particles'] = particles_layer\n",
    "        #\n",
    "        ####################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linebreaks': ['', '', '', '', '', '', '', '', '', '', '', '\\n', '', '', ''], 'syllables': [('', ['༄', '༅', '།', '།', ' ', '།', '།']), ('བཅོམ', ['་']), ('ལྡན', ['་']), ('འདས', ['་']), ('དེའི', ['་']), ('ཚེ', ['་']), ('ན', ['་']), ('ཚེ', ['་']), ('དང', ['་']), ('ལྡན', ['་']), ('པ', ['་']), ('ཀུན', ['་']), ('དགང', ['་', '།']), ('ཀུན', [' ', '་']), ('ཀུན', ['་'])]}\n"
     ]
    }
   ],
   "source": [
    "string = '''༄༅།། །།བཅོམ་ལྡན་འདས་དེའི་ཚེ་ན་ཚེ་དང་ལྡན་པ་\n",
    "ཀུན་དགང་།ཀུན ་ཀུན་'''\n",
    "prepareTib(string).syl_tuples()\n",
    "print(current_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'linebreaks': ['', '', '', '', '', '', '', '', '', '', '', '\\n', '', '', ''], 'particles': ['', '', '', '', ('དེ', 'འི'), '', '', '', '', '', 'པ', '', '', '', ''], 'syllables': [('', ['༄', '༅', '།', '།', ' ', '།', '།']), ('བཅོམ', ['་']), ('ལྡན', ['་']), ('འདས', ['་']), ('དེའི', ['་']), ('ཚེ', ['་']), ('ན', ['་']), ('ཚེ', ['་']), ('དང', ['་']), ('ལྡན', ['་']), ('པ', ['་']), ('ཀུན', ['་']), ('དགང', ['་', '།']), ('ཀུན', [' ', '་']), ('ཀུན', ['་'])]}\n"
     ]
    }
   ],
   "source": [
    "segment()\n",
    "print(current_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "་བཅོམ་ལྡན་འདས་ +('དེ', 'འི')་+ ཚེ་ན་ཚེ་དང་ལྡན་ +པ་+ ཀུན་དགང་ཀུན་ཀུན་"
     ]
    }
   ],
   "source": [
    "\n",
    "for num, syl in enumerate(current_layers['particles']):\n",
    "    if syl == '':\n",
    "        syl = current_layers['syllables'][num][0]\n",
    "        print(syl, end = '་')\n",
    "    else:\n",
    "        print(' +'+str(syl)+'་+ ', end = '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The empty strings show the  syllables where there is no suffix\n",
    "\n",
    "# \"merging-particles\" : [list-of-preceeding-suffix]\n",
    "{\n",
    "\"འི\" : [\"འ\", \"\"],\n",
    "\"འིས\" : [\"འ\", \"\"],\n",
    "\"ས\" : [\"འ\", \"\"],\n",
    "\"ར\" : [\"འ\", \"\"],\n",
    "\"འང\" : [\"འ\", \"\"],\n",
    "\"འམ\" : [\"འ\", \"\"],\n",
    "\"འོ\" : [\"འ\", \"\"]\n",
    "}\n",
    "\n",
    "# \"separate-particles\" : [list-of-preceeding-suffix]\n",
    "{\n",
    "\"གི\" : [\"ག\", \"ང\"],\n",
    "\"ཀྱི\" : [\"ད\", \"བ\", \"ས\"],\n",
    "\"གྱི\" : [\"ན\", \"མ\", \"ར\", \"ལ\"],\n",
    "\"ཡི\" : [\"འ\", \"\"],\n",
    "\"གིས\" : [\"ག\", \"ང\"],\n",
    "\"ཀྱིས\" : [\"ད\", \"བ\", \"ས\"],\n",
    "\"གྱིས\" : [\"ན\", \"མ\", \"ར\", \"ལ\"],\n",
    "\"ཡིས\" : [\"འ\", \"\"],\n",
    "\"སུ\" : [\"ས\"],\n",
    "\"ཏུ\" : [\"ག\", \"བ\", \"ད་དྲག\"],\n",
    "\"དུ\" : [\"ང\", \"ད\", \"ན\", \"མ\", \"ར\", \"ལ\"],\n",
    "\"རུ\" : [\"འ\", \"\"],\n",
    "\"སྟེ\" : [\"ག\", \"ང\", \"བ\", \"མ\", \"འ\", \"\"],\n",
    "\"ཏེ\" : [\"ན\", \"ར\", \"ལ\", \"ས\"],\n",
    "\"དེ\" : [\"ད\"],\n",
    "\"ཀྱང\" : [\"ག\", \"ད\", \"བ\", \"ས\"],\n",
    "\"ཡང\" : [\"ང\", \"ན\", \"མ\", \"འ\", \"ར\", \"ལ\", \"\"],\n",
    "\"འང\" : [\"འ\", \"\"],\n",
    "\"གམ\" : [\"ག\"],\n",
    "\"ངམ\" : [\"ང\"],\n",
    "\"དམ\" : [\"ད\"],\n",
    "\"ནམ\" : [\"ན\"],\n",
    "\"བམ\" : [\"བ\"],\n",
    "\"མམ\" : [\"མ\"],\n",
    "\"འམ\" : [\"འ\"],\n",
    "\"རམ\" : [\"ར\"],\n",
    "\"ལམ\" : [\"ལ\"],\n",
    "\"སམ\" : [\"ས\"],\n",
    "\"ཏམ\" : [\"ད་དྲག\"],\n",
    "\"པ\" : [\"ག\", \"ད\", \"བ\", \"ས\", \"ན\", \"མ\"],\n",
    "\"པོ\" : [\"ག\", \"ད\", \"བ\", \"ས\", \"ན\", \"མ\"],\n",
    "\"བ\" : [\"ང\", \"འ\", \"ར\", \"ལ\", \"\"],\n",
    "\"བོ\" : [\"ང\", \"འ\", \"ར\", \"ལ\", \"\"],\n",
    "\"གོ\" : [\"ག\"],\n",
    "\"ངོ\" : [\"ང\"],\n",
    "\"དོ\" : [\"ད\"],\n",
    "\"ནོ\" : [\"ན\"],\n",
    "\"བོ\" : [\"བ\"],\n",
    "\"མོ\" : [\"མ\"],\n",
    "\"འོ\" : [\"འ\"],\n",
    "\"རོ\" : [\"ར\"],\n",
    "\"ལོ\" : [\"ལ\"],\n",
    "\"སོ\" : [\"ས\"],\n",
    "\"ཏོ\" : [\"ད་དྲག\"],\n",
    "\"ཅིང\" : [\"ག\", \"ད\", \"བ\", \"ད་དྲག\"],\n",
    "\"ཅེས\" : [\"ག\", \"ད\", \"བ\", \"ད་དྲག\"],\n",
    "\"ཅེའོ\" : [\"ག\", \"ད\", \"བ\", \"ད་དྲག\"],\n",
    "\"ཅེ་ན\" : [\"ག\", \"ད\", \"བ\", \"ད་དྲག\"],\n",
    "\"ཅིག\" : [\"ག\", \"ད\", \"བ\", \"ད་དྲག\"],\n",
    "\"ཞིང\" : [\"ང\", \"ན\", \"མ\", \"འ\", \"ར\", \"ལ\", \"\"],\n",
    "\"ཞེས\" : [\"ང\", \"ན\", \"མ\", \"འ\", \"ར\", \"ལ\", \"ས\", \"\"],\n",
    "\"ཞེའོ\" : [\"ང\", \"ན\", \"མ\", \"འ\", \"ར\", \"ལ\", \"\"],\n",
    "\"ཞེ་ན\" : [\"ང\", \"ན\", \"མ\", \"འ\", \"ར\", \"ལ\", \"\"],\n",
    "\"ཞིག\" : [\"ང\", \"ན\", \"མ\", \"འ\", \"ར\", \"ལ\", \"\"],\n",
    "\"ཤིང\" : [\"ས\"],\n",
    "\"ཤེའོ\" : [\"ས\"],\n",
    "\"ཤེ་ན\" : [\"ས\"],\n",
    "\"ཤིག\" : [\"ས\"]\n",
    "}\n",
    "\n",
    "//\"གི\" \"ཀྱི\" \"གྱི\" \"ཡི\" \"གིས\" \"ཀྱིས\" \"གྱིས\" \"ཡིས\" \"སུ\" \"ཏུ\" \"དུ\" \"རུ\" \"སྟེ\" \"ཏེ\" \"དེ\" \"གམ\" \"ངམ\" \"དམ\" \"ནམ\" \"བམ\" \"མམ\" \"རམ\" \"ལམ\" \"སམ\" \"ཏམ\" \"པ\" \"པོ\" \"བ\" \"བོ\" \"གོ\" \"ངོ\" \"དོ\" \"ནོ\" \"བོ\" \"མོ\" \"འོ\" \"རོ\" \"ལོ\" \"སོ\" \"ཏོ\" \n",
    "{\"གི\" : true, \"ཀྱི\" : true, \"གྱི\" : true, \"ཡི\" : true, \"གིས\" : true, \"ཀྱིས\" : true, \"གྱིས\" : true, \"ཡིས\" : true, \"སུ\" : true, \"ཏུ\" : true, \"དུ\" : true, \"རུ\" : true, \"སྟེ\" : true, \"ཏེ\" : true, \"དེ\" : true, \"གམ\" : true, \"ངམ\" : true, \"དམ\" : true, \"ནམ\" : true, \"བམ\" : true, \"མམ\" : true, \"རམ\" : true, \"ལམ\" : true, \"སམ\" : true, \"ཏམ\" : true, \"པ\" : true, \"པོ\" : true, \"བ\" : true, \"བོ\" : true, \"གོ\" : true, \"ངོ\" : true, \"དོ\" : true, \"ནོ\" : true, \"བོ\" : true, \"མོ\" : true, \"འོ\" : true, \"རོ\" : true, \"ལོ\" : true, \"སོ\" : true, \"ཏོ\" : true}\n",
    "\n",
    "//\"ཅི\" \"ཇི\" \"ཡིན\" \"མིན\" \"ཡོད\" \"མེད\" \"དང\" \"ལ\" \"ལས\" \"ན\" \"ནི\" \n",
    "//\"ཀྱང\" \"ཡང\" \"ཅིང\" \"ཅེས\" \"ཅེའོ\" \"ཅིག\" \"ཞིང\" \"ཞེས\" \"ཞེའོ\" \"ཞིག\" \"ཤིང\" \"ཤེའོ\" \"ཤིག\" \"གིན\" \"གྱིན\"\n",
    "{\"ཅི\" : true, \"ཇི\" : true, \"ཡིན\" : true, \"མིན\" : true, \"ཡོད\" : true, \"མེད\" : true, \"དང\" : true, \"ལ\" : true, \"ལས\" : true, \"ན\" : true, \"ནི\" : true, \"ཀྱང\" : true, \"ཡང\" : true, \"ཅིང\" : true, \"ཅེས\" : true, \"ཅེའོ\" : true, \"ཅིག\" : true, \"ཞིང\" : true, \"ཞེས\" : true, \"ཞེའོ\" : true, \"ཞིག\" : true, \"ཤིང\" : true, \"ཤེའོ\" : true, \"ཤིག\" : true, \"གིན\" : true, \"གྱིན\" : true, \n",
    "\n",
    "//\"ཤེ་ན\" \"ཞེ་ན\" \"ཅེ་ན\" \n",
    "{\"ཤེ་ན\" : true, \"ཞེ་ན\" : true, \"ཅེ་ན\" : true, \n",
    "\n",
    "ལྡན་"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
